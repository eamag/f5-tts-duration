{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68fcef367674729befcf8929cc4dfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EN-B000001.tar:   0%|          | 0.00/2.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc2880e00b944919ead3db714228e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EN-B001001.tar:   0%|          | 0.00/105M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e576e0149e74409d95d2e6832db52e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "path = \"EN/*001.tar\"\n",
    "hfdataset = load_dataset(\"amphion/Emilia-Dataset\", data_files={\"en\": path}, split=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "niLb5KgxUClY",
    "outputId": "1ddd4779-8a7c-4f3d-992c-693cefccda43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 21852160\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from f5_tts.model.duration import DurationPredictor, DurationTransformer\n",
    "from f5_tts.model.trainer import DurationTrainer\n",
    "from f5_tts.model.dataset import TextAudioDataset, HFDataset\n",
    "\n",
    "vocab_path = \"data/de/vocab.txt\"\n",
    "vocab = {v: i for i, v in enumerate(Path(vocab_path).read_text().split(\"\\n\"))}\n",
    "\n",
    "duration_predictor = DurationPredictor(\n",
    "    transformer=DurationTransformer(\n",
    "        dim=512,\n",
    "        depth=8,\n",
    "        heads=8,\n",
    "        text_dim=512,\n",
    "        ff_mult=2,\n",
    "        conv_layers=2,\n",
    "        text_num_embeds=len(vocab) - 1,\n",
    "    ),\n",
    "    vocab_char_map=vocab,\n",
    ")\n",
    "print(\n",
    "    f\"Trainable parameters: {sum(p.numel() for p in duration_predictor.parameters() if p.requires_grad)}\"\n",
    ")\n",
    "\n",
    "optimizer = AdamW(duration_predictor.parameters(), lr=7.5e-5)\n",
    "\n",
    "trainer = DurationTrainer(\n",
    "    duration_predictor,\n",
    "    optimizer,\n",
    "    num_warmup_steps=5000,\n",
    "    # accelerate_kwargs = {\"mixed_precision\": \"fp16\", \"log_with\": \"wandb\"}\n",
    "    accelerate_kwargs={\"mixed_precision\": \"no\"},\n",
    ")\n",
    "\n",
    "epochs = 25\n",
    "max_batch_tokens = 16_000\n",
    "\n",
    "# train_dataset = TextAudioDataset(\n",
    "#     folder = Path(\"LibriTTS_R\").expanduser(),\n",
    "#     audio_extensions = [\"wav\"],\n",
    "#     max_duration = 44\n",
    "# )\n",
    "train_dataset = HFDataset(hfdataset)\n",
    "print(\"Training...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.load_checkpoint(\"f5tts_duration_3000.pt\")\n",
    "trainer.load_checkpoint(\"../f5tts_duration.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl = trainer.train(train_dataset, epochs, max_batch_tokens, num_workers=0, save_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "batch = next(iter(dl))\n",
    "m = trainer.accelerator.unwrap_model(trainer.model)\n",
    "text_inputs = batch[\"text\"]\n",
    "mel_spec = rearrange(batch[\"mel\"], \"b d n -> b n d\")\n",
    "mel_lengths = batch[\"mel_lengths\"]\n",
    "\n",
    "loss = m(\n",
    "    mel_spec, text=text_inputs, lens=mel_lengths, return_loss=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file, save_model\n",
    "import torch\n",
    "\n",
    "save_model(trainer.accelerator.unwrap_model(trainer.model), \"duration_v2.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([72.9162, 67.5215, 68.1405, 79.3960, 72.2256, 75.3841, 68.6786, 68.8755,\n",
       "        74.7844, 69.5419, 67.1713, 72.2198, 70.6283, 71.7877, 75.4355, 67.6825,\n",
       "        71.8702, 68.8977, 67.4177], device='mps:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_RATE = 24_000\n",
    "HOP_LENGTH = 256\n",
    "SAMPLES_PER_SECOND = SAMPLE_RATE / HOP_LENGTH\n",
    "loss*SAMPLES_PER_SECOND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 352,  600,  378,  644,  656,  706,  289, 1680, 1797,  538,  698, 1479,\n",
       "         761,  500,  282,  363,  425,  528,  656, 1400], device='mps:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['mel_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5553, 0.6148, 0.5615, 0.6153, 0.6178, 0.6223, 0.5385, 0.6636, 0.6613,\n",
       "        0.6009, 0.6223, 0.6581, 0.6228, 0.5864, 0.5168, 0.5600, 0.5809, 0.5982,\n",
       "        0.6100, 0.6644], device='mps:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
